{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rosbag\n",
    "import rospy\n",
    "import tf\n",
    "import numpy as np\n",
    "import tf2_ros\n",
    "import tf2_geometry_msgs\n",
    "\n",
    "\n",
    "data_already_loaded = False\n",
    "\n",
    "bag_dir_diff = '../../../dissertation_data/diff_2'\n",
    "bag_dir_omni = '../../../dissertation_data/omni'\n",
    "\n",
    "# List all .bag files in the directory\n",
    "bag_files_diff = sorted([f for f in os.listdir(bag_dir_diff) if f.endswith('.bag')])\n",
    "bag_files_omni = sorted([f for f in os.listdir(bag_dir_omni) if f.endswith('.bag')])\n",
    "\n",
    "bag_file_diff_full = [bag_dir_diff + '/' + bag_file for bag_file in bag_files_diff]\n",
    "bag_file_omni_full = [bag_dir_omni + '/' + bag_file for bag_file in bag_files_omni]\n",
    "\n",
    "print('Diff:')\n",
    "for bag_file in bag_file_diff_full:\n",
    "    print(bag_file)\n",
    "\n",
    "print('Omni:')\n",
    "for bag_file in bag_file_omni_full:\n",
    "    print(bag_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available topic list\n",
    "# /L1/cmd_vel\n",
    "# /L1/imu\n",
    "# /L1/limo_status\n",
    "# /L1/odom\n",
    "# /P1/control_point\n",
    "# /P1/which_route_point\n",
    "# /Pioneer_path\n",
    "# /RosAria/battery_recharge_state\n",
    "# /RosAria/battery_voltage\n",
    "# /RosAria/bumper_state\n",
    "# /RosAria/cmd_vel\n",
    "# /RosAria/motors_state\n",
    "# /RosAria/parameter_descriptions\n",
    "# /RosAria/parameter_updates\n",
    "# /RosAria/pose\n",
    "# /RosAria/sonar\n",
    "# /RosAria/sonar_pointcloud2\n",
    "# /base_points\n",
    "# /closest_points\n",
    "# /closest_points_text\n",
    "# /emergency_flag\n",
    "# /filtered_closest_points\n",
    "# /jacobian\n",
    "# /last_point_inside_map\n",
    "# /local_map\n",
    "# /local_map_new\n",
    "# /local_path\n",
    "# /map\n",
    "# /map_metadata\n",
    "# /map_topic_for_local_rrt\n",
    "# /matched_base_points\n",
    "# /potential\n",
    "# /potential_arrows\n",
    "# /rosout\n",
    "# /rosout_agg\n",
    "# /rplidar/scan\n",
    "# /rrt_nodes_\n",
    "# /rrt_path\n",
    "# /slam_gmapping/entropy\n",
    "# /smoothed_local_path\n",
    "# /start_point_local_map\n",
    "# /tf\n",
    "# /tf_static\n",
    "# /traveled_path\n",
    "# /v\n",
    "# /vrpn_client_node/L1/pose\n",
    "# /vrpn_client_node/P1/pose\n",
    "# /which_route_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('time_values.csv')\n",
    "\n",
    "# Function to convert string to list and handle errors\n",
    "def convert_to_list(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # print(f\"Error converting {x}: {e}\")\n",
    "        return x  # Return original value if conversion fails\n",
    "\n",
    "# Apply the conversion function to each column\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(convert_to_list)\n",
    "\n",
    "# Print the DataFrame to inspect\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the TF BUFFER for all bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_already_loaded:\n",
    "    rospy.init_node('tf_buffer_node', anonymous=True)\n",
    "    cache_time = rospy.Duration(172800) #Two days\n",
    "    tf_buffer = tf2_ros.Buffer(cache_time=cache_time)\n",
    "\n",
    "    go_times_omni = df.iloc[:, 1].values\n",
    "    back_times_omni = df.iloc[:, 2].values\n",
    "\n",
    "    go_times_diff = df.iloc[:, 3].values\n",
    "    back_times_diff = df.iloc[:, 4].values\n",
    "\n",
    "    # Omni bags\n",
    "    for i, bag_file in enumerate(bag_file_omni_full):\n",
    "        bag = rosbag.Bag(bag_file, 'r')\n",
    "        first_time = None\n",
    "\n",
    "        go_time_begin = go_times_omni[i][0] - 1 # 1 second before\n",
    "        go_time_end = go_times_omni[i][1] + 1 # 1 second after\n",
    "        back_time_begin = back_times_omni[i][0] - 1\n",
    "        back_time_end = back_times_omni[i][1] + 1\n",
    "\n",
    "        for topic, msg, t in bag.read_messages(topics=['/tf', '/tf_static', '/vrpn_client_node/L1/pose']):\n",
    "\n",
    "            if topic == '/tf_static':\n",
    "                for transform in msg.transforms:\n",
    "                    tf_buffer.set_transform(transform, 'default_authority')\n",
    "            \n",
    "            if first_time is None:\n",
    "                if topic == '/vrpn_client_node/L1/pose':\n",
    "                    first_time = t.to_sec()\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            elapsed_time = t.to_sec() - first_time\n",
    "\n",
    "            if ((elapsed_time >= go_time_begin) and (elapsed_time <= go_time_end)) or ((elapsed_time >= back_time_begin) and (elapsed_time <= back_time_end)):\n",
    "                if topic == '/tf':\n",
    "                    for transform in msg.transforms:\n",
    "                        tf_buffer.set_transform(transform, 'default_authority')\n",
    "\n",
    "        bag.close()\n",
    "\n",
    "    # Diff bags\n",
    "    for i, bag_file in enumerate(bag_file_diff_full):\n",
    "        bag = rosbag.Bag(bag_file, 'r')\n",
    "        first_time = None\n",
    "\n",
    "        go_time_begin = go_times_diff[i][0] - 1\n",
    "        go_time_end = go_times_diff[i][1] + 1\n",
    "        back_time_begin = back_times_diff[i][0] - 1\n",
    "        back_time_end = back_times_diff[i][1] + 1\n",
    "\n",
    "        for topic, msg, t in bag.read_messages(topics=['/tf', '/tf_static', '/vrpn_client_node/L1/pose']):\n",
    "\n",
    "            if topic == '/tf_static':\n",
    "                for transform in msg.transforms:\n",
    "                    tf_buffer.set_transform(transform, 'default_authority')\n",
    "            \n",
    "            if first_time is None:\n",
    "                if topic == '/vrpn_client_node/L1/pose':\n",
    "                    first_time = t.to_sec()\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            elapsed_time = t.to_sec() - first_time\n",
    "\n",
    "            if ((elapsed_time >= go_time_begin) and (elapsed_time <= go_time_end)) or ((elapsed_time >= back_time_begin) and (elapsed_time <= back_time_end)):\n",
    "                if topic == '/tf':\n",
    "                    for transform in msg.transforms:\n",
    "                        tf_buffer.set_transform(transform, 'default_authority')\n",
    "\n",
    "        bag.close()\n",
    "\n",
    "# 3m 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poses Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_already_loaded:\n",
    "    # Separate times to cut the data\n",
    "    go_times = df.iloc[:, 1].values\n",
    "    back_times = df.iloc[:, 2].values\n",
    "\n",
    "    poses_diff_go = {}\n",
    "    poses_diff_back = {}\n",
    "\n",
    "    base_points_diff_go = {}\n",
    "    base_points_diff_back = {}\n",
    "\n",
    "    lidar_diff_go = {}\n",
    "    lidar_diff_back = {}\n",
    "\n",
    "    map_diff = {}\n",
    "\n",
    "    local_map_diff_go = {}\n",
    "    local_map_diff_back = {}\n",
    "\n",
    "    local_path_diff_go = {}\n",
    "    local_path_diff_back = {}\n",
    "\n",
    "    smoothed_local_path_diff_go = {}\n",
    "    smoothed_local_path_diff_back = {}\n",
    "\n",
    "    for i, bag_file in enumerate(bag_file_diff_full):\n",
    "        go_time_begin = go_times[i][0]\n",
    "        go_time_end = go_times[i][1]\n",
    "        back_time_begin = back_times[i][0]\n",
    "        back_time_end = back_times[i][1]\n",
    "\n",
    "        bag = rosbag.Bag(bag_file, 'r')\n",
    "        poses_diff_go[i] = []\n",
    "        poses_diff_back[i] = []\n",
    "\n",
    "        base_points_diff_go[i] = []\n",
    "        base_points_diff_back[i] = []\n",
    "\n",
    "        lidar_diff_go[i] = []\n",
    "        lidar_diff_back[i] = []\n",
    "\n",
    "        map_diff[i] = None\n",
    "\n",
    "        local_map_diff_go[i] = []\n",
    "        local_map_diff_back[i] = []\n",
    "\n",
    "        local_path_diff_go[i] = []\n",
    "        local_path_diff_back[i] = []\n",
    "\n",
    "        smoothed_local_path_diff_go[i] = []\n",
    "        smoothed_local_path_diff_back[i] = []\n",
    "\n",
    "        first_time = None\n",
    "\n",
    "        for topic, msg, t in bag.read_messages(topics=['/vrpn_client_node/L1/pose', '/base_points', '/rplidar/scan', '/map', '/local_map', '/local_path', '/smoothed_local_path' ]):\n",
    "            \n",
    "            if first_time is None:\n",
    "                if topic == '/vrpn_client_node/L1/pose':\n",
    "                    first_time = t.to_sec()\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            elapsed_time = t.to_sec() - first_time\n",
    "\n",
    "            if ((elapsed_time >= go_time_begin) and (elapsed_time <= go_time_end)):\n",
    "                if topic == '/base_points':\n",
    "                    base_points_diff_go[i].append(msg)\n",
    "                \n",
    "                if topic == '/rplidar/scan':\n",
    "                    lidar_diff_go[i].append(msg)\n",
    "                \n",
    "                if topic == '/map':\n",
    "                    map_diff[i] = msg\n",
    "                \n",
    "                if topic == '/local_map':\n",
    "                    local_map_diff_go[i].append(msg)\n",
    "                \n",
    "                if topic == '/local_path':\n",
    "                    local_path_diff_go[i].append(msg)\n",
    "                \n",
    "                if topic == '/smoothed_local_path':\n",
    "                    smoothed_local_path_diff_go[i].append(msg)\n",
    "                \n",
    "                if topic == '/vrpn_client_node/L1/pose':\n",
    "                    poses_diff_go[i].append(msg)\n",
    "\n",
    "            if ((elapsed_time >= back_time_begin) and (elapsed_time <= back_time_end)):\n",
    "                if topic == '/base_points':\n",
    "                    base_points_diff_back[i].append(msg)\n",
    "                \n",
    "                if topic == '/rplidar/scan':\n",
    "                    lidar_diff_back[i].append(msg)\n",
    "                \n",
    "                if topic == '/local_map':\n",
    "                    local_map_diff_back[i].append(msg)\n",
    "                \n",
    "                if topic == '/local_path':\n",
    "                    local_path_diff_back[i].append(msg)\n",
    "                \n",
    "                if topic == '/smoothed_local_path':\n",
    "                    smoothed_local_path_diff_back[i].append(msg)\n",
    "                \n",
    "                if topic == '/vrpn_client_node/L1/pose':\n",
    "                    poses_diff_back[i].append(msg)\n",
    "        bag.close()\n",
    "\n",
    "    del go_times, back_times\n",
    "# 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for positions_diff_go\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in poses_diff_go.keys():\n",
    "    positions = np.array([[pose.pose.position.x, pose.pose.position.y] for pose in poses_diff_go[i]])\n",
    "    plt.scatter(positions[:, 0], positions[:, 1], label=f'Diff Position {i}', s=1)\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.axis('equal')\n",
    "plt.title('Scatter Plot of Go Poses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limit_data_frequency(data, times, max_frequency_hz):\n",
    "    max_frequency_sec = 1 / max_frequency_hz\n",
    "\n",
    "    new_data = []\n",
    "    \n",
    "    last_time = None\n",
    "    for i, time in enumerate(times):\n",
    "        if last_time is None:\n",
    "            last_time = time\n",
    "            new_data.append(data[i])\n",
    "            continue\n",
    "\n",
    "        dt = time - last_time\n",
    "\n",
    "        if dt >= max_frequency_sec:\n",
    "            new_data.append(data[i])\n",
    "            last_time = time\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "# Limit the frequency of the data\n",
    "max_frequency_hz = 10\n",
    "poses_diff_go_filtered = {}\n",
    "poses_diff_back_filtered = {}\n",
    "\n",
    "for i in poses_diff_go.keys():\n",
    "    pose_diff_go_times = [pose.header.stamp.to_sec() for pose in poses_diff_go[i]]\n",
    "    poses_diff_go_filtered[i] = limit_data_frequency(poses_diff_go[i], pose_diff_go_times, max_frequency_hz)\n",
    "\n",
    "    pose_diff_back_times = [pose.header.stamp.to_sec() for pose in poses_diff_back[i]]\n",
    "    poses_diff_back_filtered[i] = limit_data_frequency(poses_diff_back[i], pose_diff_back_times, max_frequency_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_already_loaded:\n",
    "    # Yaw values in radians\n",
    "    # Orientations   \n",
    "    orientations_diff_go_filtered = {}\n",
    "    orientations_diff_back_filtered = {}\n",
    "    for i in range(len(poses_diff_go)):\n",
    "        orientations_diff_go_filtered[i] = []\n",
    "        orientations_diff_back_filtered[i] = []\n",
    "        for pose in poses_diff_go_filtered[i]:\n",
    "            orientation_q = pose.pose.orientation\n",
    "            orientation_list = [orientation_q.x, orientation_q.y, orientation_q.z, orientation_q.w]\n",
    "            roll, pitch, yaw = tf.transformations.euler_from_quaternion(orientation_list)\n",
    "            orientations_diff_go_filtered[i].append(yaw)\n",
    "        for pose in poses_diff_back_filtered[i]:\n",
    "            orientation_q = pose.pose.orientation\n",
    "            orientation_list = [orientation_q.x, orientation_q.y, orientation_q.z, orientation_q.w]\n",
    "            roll, pitch, yaw = tf.transformations.euler_from_quaternion(orientation_list)\n",
    "            orientations_diff_back_filtered[i].append(yaw)\n",
    "        \n",
    "        orientations_diff_go_filtered[i] = np.array(orientations_diff_go_filtered[i])\n",
    "        orientations_diff_back_filtered[i] = np.array(orientations_diff_back_filtered[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_velocity_diff_go = {}\n",
    "angular_acceleration_diff_go = {}\n",
    "\n",
    "angular_velocity_diff_back = {}\n",
    "angular_acceleration_diff_back = {}\n",
    "\n",
    "for i in orientations_diff_go_filtered.keys():\n",
    "    # Calculate angular velocity (difference in yaw divided by time difference)\n",
    "    angular_velocity_diff_go[i] = np.diff(orientations_diff_go_filtered[i]) / np.diff([pose.header.stamp.to_sec() for pose in poses_diff_go_filtered[i]])\n",
    "    \n",
    "    # Calculate angular acceleration (difference in angular velocity divided by time difference)\n",
    "    angular_acceleration_diff_go[i] = np.diff(angular_velocity_diff_go[i]) / np.diff([pose.header.stamp.to_sec() for pose in poses_diff_go_filtered[i][1:]])\n",
    "\n",
    "for i in orientations_diff_back_filtered.keys():\n",
    "    # Calculate angular velocity (difference in yaw divided by time difference)\n",
    "    angular_velocity_diff_back[i] = np.diff(orientations_diff_back_filtered[i]) / np.diff([pose.header.stamp.to_sec() for pose in poses_diff_back_filtered[i]])\n",
    "    \n",
    "    # Calculate angular acceleration (difference in angular velocity divided by time difference)\n",
    "    angular_acceleration_diff_back[i] = np.diff(angular_velocity_diff_back[i]) / np.diff([pose.header.stamp.to_sec() for pose in poses_diff_back_filtered[i][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butterworth_filter(data, cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Define thresholds\n",
    "upper_threshold = 1000\n",
    "lower_threshold = -1000\n",
    "\n",
    "# Filter angular velocity\n",
    "filtered_angular_velocity_diff = {}\n",
    "smoothed_velocities = {}\n",
    "elapsed_time = {}\n",
    "smoothed_accelerations = {}\n",
    "for i in angular_velocity_diff_go.keys():\n",
    "    filtered_angular_velocity_diff[i] = np.clip(angular_velocity_diff_go[i], lower_threshold, upper_threshold)\n",
    "\n",
    "    cutoff_frequency = 1.7\n",
    "    new_sampling_rate = 1 / np.mean(np.diff([pose.header.stamp.to_sec() for pose in poses_diff_go_filtered[i]]))\n",
    "    print(f\"New sampling rate: {new_sampling_rate}\")\n",
    "\n",
    "    smoothed_velocities[i] = butterworth_filter(filtered_angular_velocity_diff[i], cutoff_frequency, new_sampling_rate)\n",
    "    elapsed_time[i] = np.array([pose.header.stamp.to_sec() - poses_diff_go_filtered[i][0].header.stamp.to_sec() for pose in poses_diff_go_filtered[i]])\n",
    "    elapsed_time[i] = elapsed_time[i][:-1]\n",
    "\n",
    "    smoothed_accelerations[i] = np.diff(smoothed_velocities[i]) / np.diff(elapsed_time[i])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot angular velocity\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(elapsed_time[0], angular_velocity_diff_go[0], label='Angular Velocity')\n",
    "plt.plot(elapsed_time[0], smoothed_velocities[0], label='Smoothed Angular Velocity', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Angular Velocity (rad/s)')\n",
    "plt.title('Angular Velocity over Time')\n",
    "plt.legend()\n",
    "\n",
    "# Plot angular acceleration\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(smoothed_accelerations[0], label='Angular Acceleration', color='orange')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Angular Acceleration (rad/s^2)')\n",
    "plt.title('Angular Acceleration over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filter_lidar_scans(lidar_data, elapsed_time, accelerations, velocities, acceleration_threshold=0.4, velocity_threshold=0.15):\n",
    "    # Calculate the elapsed time for each lidar scan\n",
    "    lidar_elapsed_time = np.array([lidar.header.stamp.to_sec() - lidar_data[0].header.stamp.to_sec() for lidar in lidar_data])\n",
    "\n",
    "    filtered_lidar_data = []\n",
    "\n",
    "    # Iterate through lidar scans and their corresponding elapsed times\n",
    "    for lidar, time in zip(lidar_data, lidar_elapsed_time):\n",
    "        # Get the index of the acceleration/velocity value closest to the time of the lidar scan\n",
    "        index = np.argmin(np.abs(elapsed_time - time))\n",
    "\n",
    "        # Retrieve the corresponding acceleration and velocity values\n",
    "        acceleration_value = accelerations[index - 1]\n",
    "        velocity_value = velocities[index - 1]\n",
    "\n",
    "        # Apply filtering conditions based on acceleration and velocity thresholds\n",
    "        if (np.abs(acceleration_value) < acceleration_threshold) and (np.abs(velocity_value) < velocity_threshold):\n",
    "            filtered_lidar_data.append(lidar)\n",
    "\n",
    "    return filtered_lidar_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration_threshold = 0.1\n",
    "velocity_threshold = 0.1\n",
    "\n",
    "lidar_diff_go_filtered = {}\n",
    "for i in range(len(lidar_diff_go)):\n",
    "    lidar_diff_go_filtered[i] = filter_lidar_scans(lidar_diff_go[i], elapsed_time[i], smoothed_accelerations[i], smoothed_velocities[i], acceleration_threshold, velocity_threshold)\n",
    "\n",
    "print(len(lidar_diff_go[0]), len(lidar_diff_go_filtered[0]))\n",
    "print(len(lidar_diff_go[1]), len(lidar_diff_go_filtered[1]))\n",
    "print(len(lidar_diff_go[2]), len(lidar_diff_go_filtered[2]))\n",
    "print(len(lidar_diff_go[3]), len(lidar_diff_go_filtered[3]))\n",
    "print(len(lidar_diff_go[4]), len(lidar_diff_go_filtered[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import laser_geometry\n",
    "import tf2_ros\n",
    "import tf2_sensor_msgs\n",
    "\n",
    "def transform_laser_scans_to_world_frame(filtered_lidar_scans, tf_buffer, target_frame='world', max_range=6.0):\n",
    "    \"\"\"\n",
    "    Transforms a list of LaserScan messages to the specified world frame and returns the transformed PointCloud2 data.\n",
    "\n",
    "    Args:\n",
    "        filtered_lidar_scans (list): List of LaserScan messages to be transformed.\n",
    "        tf_buffer (tf2_ros.Buffer): TF buffer to lookup transforms.\n",
    "        target_frame (str): The target frame to transform the data to. Default is 'world'.\n",
    "        max_range (float): The maximum range to filter LaserScan points. Points greater than max_range will be set to infinity.\n",
    "\n",
    "    Returns:\n",
    "        list: List of transformed PointCloud2 messages in the target frame.\n",
    "    \"\"\"\n",
    "    # Create a laser projector object to convert LaserScan to PointCloud2\n",
    "    projector = laser_geometry.LaserProjection()\n",
    "    lidar_world_frame = []\n",
    "\n",
    "    # Iterate over each LaserScan message\n",
    "    for original_msg in filtered_lidar_scans:\n",
    "        try:\n",
    "            # Create a deep copy of the original LaserScan message to avoid modifying it\n",
    "            msg = copy.deepcopy(original_msg)\n",
    "            \n",
    "            # Get the transform from the source frame to the target frame at the message timestamp\n",
    "            transform = tf_buffer.lookup_transform(target_frame, msg.header.frame_id, msg.header.stamp)\n",
    "\n",
    "            # Filter out scan messages with ranges greater than max_range (work on the copied data)\n",
    "            msg.ranges = [r if r <= max_range else float('inf') for r in msg.ranges]\n",
    "\n",
    "            # Convert LaserScan to PointCloud2 using the laser geometry projector\n",
    "            cloud = projector.projectLaser(msg)\n",
    "\n",
    "            # Transform the PointCloud2 to the target frame\n",
    "            transformed_cloud = tf2_sensor_msgs.do_transform_cloud(cloud, transform)\n",
    "\n",
    "            # Append the transformed PointCloud2 to the list\n",
    "            lidar_world_frame.append(transformed_cloud)\n",
    "\n",
    "        except tf2_ros.LookupException as e:\n",
    "            print(f\"LookupException: {e}\")\n",
    "        except tf2_ros.ExtrapolationException as e:\n",
    "            print(f\"ExtrapolationException: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Transformation failed at time {msg.header.stamp.to_sec()}: {e}\")\n",
    "\n",
    "    return lidar_world_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_diff_go_filtered_world = {}\n",
    "\n",
    "for i in range(len(lidar_diff_go_filtered)):\n",
    "    laser_diff_go_filtered_world[i] = transform_laser_scans_to_world_frame(lidar_diff_go_filtered[i], tf_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_msgs.point_cloud2 as pc2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for transformed_cloud in laser_diff_go_filtered_world[4]:\n",
    "    # Read the points from the PointCloud2 message\n",
    "    points = list(pc2.read_points(transformed_cloud, field_names=(\"x\", \"y\", \"z\"), skip_nans=True))\n",
    "\n",
    "    # Convert to numpy array for easier manipulation\n",
    "    points_array = np.array(points)\n",
    "\n",
    "    # Scatter plot the points\n",
    "    plt.scatter(points_array[:, 0], points_array[:, 1], c='blue', s=1)\n",
    "    \n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot of Transformed PointCloud2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_msgs.point_cloud2 as pc2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "transformed_cloud = laser_diff_go_filtered_world[0][-5]\n",
    "\n",
    "# Read the points from the PointCloud2 message\n",
    "points = list(pc2.read_points(transformed_cloud, field_names=(\"x\", \"y\", \"z\"), skip_nans=True))\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "points_array = np.array(points)\n",
    "\n",
    "# Scatter plot the points\n",
    "plt.scatter(points_array[:, 0], points_array[:, 1], c='blue', s=1)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.axis('equal')\n",
    "plt.title('Scatter Plot of Transformed PointCloud2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
